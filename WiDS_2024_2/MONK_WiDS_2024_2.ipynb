{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Team Chat"
      ],
      "metadata": {
        "id": "sqtku5fjZ825"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4BpjHEj4yFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5dfca0c-48a1-4844-88bc-f10903a33fbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hellooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n"
          ]
        }
      ],
      "source": [
        "print(\"hellooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Howu is!!!!!!!!!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85fCoThF583f",
        "outputId": "1703e086-639c-403e-b0f8-fa6cc6f7401b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Howu is!!!!!!!!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Woooooooo ( ﾉ･o･ )ﾉ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43wBhLDmnVQj",
        "outputId": "26ebb8a4-64d6-435c-ba13-164e40b540f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Woooooooo ( ﾉ･o･ )ﾉ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"sdaf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJsryxlkH1OE",
        "outputId": "b29a1151-df85-4c59-e6df-bdedf63028a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sdaf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Libraries"
      ],
      "metadata": {
        "id": "1D0GQWuHzlLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "from google.colab import files\n",
        "from sklearn import svm\n",
        "#from sklearn.impute import SimpleImputer\n",
        "#KNNImputer, IterativeImputer\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "5f6w7Nw0zjS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Data"
      ],
      "metadata": {
        "id": "NendqkNZznTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_url = \"https://raw.githubusercontent.com/NoorAbuGhz/WiDS-2024/4f7161a684f1bf10d4f1c5a50ef811372dd5fa96/test.csv\"\n",
        "train_url = \"https://raw.githubusercontent.com/NoorAbuGhz/WiDS-2024/4f7161a684f1bf10d4f1c5a50ef811372dd5fa96/train.csv\"\n",
        "solution_template_url = \"https://raw.githubusercontent.com/NoorAbuGhz/WiDS-2024/4f7161a684f1bf10d4f1c5a50ef811372dd5fa96/solution_template.csv\"\n",
        "\n",
        "test = pd.read_csv(test_url)\n",
        "train = pd.read_csv(train_url)\n",
        "sample = pd.read_csv(solution_template_url)\n",
        "\n",
        "patients = test['patient_id']"
      ],
      "metadata": {
        "id": "R2eASMmrItyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Exlporation"
      ],
      "metadata": {
        "id": "58KAnMr-zfYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['patient_id'].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87SYeFd4KUG5",
        "outputId": "fdfb421b-a62a-41f7-becd-4a9404b68c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13173"
            ]
          },
          "metadata": {},
          "execution_count": 534
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krMfM_3KkFWk",
        "outputId": "4856d11c-4c3c-404d-b3a1-5101d0c0e4a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13173, 152)\n",
            "(5646, 151)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['metastatic_first_novel_treatment'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xId--Btln4LI",
        "outputId": "beabf195-2df6-46f7-f0cd-d2be20f13ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan, 'OLAPARIB', 'PEMBROLIZUMAB'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 536
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking number of unique values per column\n",
        "# for col in test.columns:\n",
        "#   print(col,\"\\t\",train[col].nunique())"
      ],
      "metadata": {
        "id": "oGhuXl8GnhoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.patient_race.unique())\n",
        "\n",
        "# patient_race - Asian, African American, Hispanic or Latino, White, Other Race\n",
        "# Columns related to race: race_white, race_black, race_asian, race_native, race_pacific, race_other, race_multiple, hispanic\n",
        "\n",
        "# Asian - race_asian\n",
        "# African American - race_black\n",
        "# Hispanic or Latino - hispanic\n",
        "# Asian - race_asian\n",
        "# Other - race_other, race_multiple, race_native, race_pacific"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKp1NqSHpl6C",
        "outputId": "1aadb923-e969-4953-dd22-951899627973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nan 'White' 'Hispanic' 'Black' 'Other' 'Asian']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking columns with null\n",
        "# for col in test.columns:\n",
        "#   if train[col].isnull().sum() > 0:\n",
        "#     print(col,\"\\t\",train[col].isnull().sum())\n",
        "\n",
        "# 13173 total rows"
      ],
      "metadata": {
        "id": "NwI1lR7ZpPD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = test['income_household_median']\n",
        "s.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r98O3oOGT8a",
        "outputId": "eb6ac00e-8177-4483-a391-27d2225843a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count      5646.000000\n",
              "mean      73712.310602\n",
              "std       20225.771198\n",
              "min       32935.380000\n",
              "25%       61075.130000\n",
              "50%       69407.350000\n",
              "75%       82970.380000\n",
              "max      164119.200000\n",
              "Name: income_household_median, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 540
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dropping Columns"
      ],
      "metadata": {
        "id": "4Vn13uBsrJv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train=train.drop(train.loc[:, 'age_under_10':'age_over_80'].columns, axis=1)\n",
        "# train=train.drop(train.loc[:, 'married':'income_household_15_to_20'].columns, axis=1)\n",
        "# train=train.drop(train.loc[:, 'income_household_20_to_25':'income_individual_median'].columns, axis=1)\n",
        "# train=train.drop(train.loc[:, 'home_ownership':'labor_force_participation'].columns, axis=1)\n",
        "\n",
        "\n",
        "train=train.drop(train.loc[:, 'unemployment_rate':'farmer'].columns, axis=1)\n",
        "# train=train.drop(train.loc[:, 'limited_english':'veteran'].columns, axis=1)\n",
        "# after dropping the score got a little better (0.09)\n",
        "train=train.drop(train.loc[:, 'Average of Jan-13':'Average of Dec-18'].columns, axis=1)\n",
        "\n",
        "# id\n",
        "# train=train.drop(['patient_id'], axis=1)\n",
        "# a lot of null\n",
        "train=train.drop(['payer_type','bmi'], axis=1)\n",
        "# basically empty\n",
        "train=train.drop(['metastatic_first_novel_treatment','metastatic_first_novel_treatment_type'], axis=1)\n",
        "# one unique\n",
        "train=train.drop(['patient_gender'], axis=1)"
      ],
      "metadata": {
        "id": "ogxxVFaSc7AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test=test.drop(test.loc[:, 'age_under_10':'age_over_80'].columns, axis=1)\n",
        "# test=test.drop(test.loc[:, 'married':'income_household_15_to_20'].columns, axis=1)\n",
        "# test=test.drop(test.loc[:, 'income_household_20_to_25':'income_individual_median'].columns, axis=1)\n",
        "# test=test.drop(test.loc[:, 'home_ownership':'labor_force_participation'].columns, axis=1)\n",
        "\n",
        "\n",
        "test=test.drop(test.loc[:, 'unemployment_rate':'farmer'].columns, axis=1)\n",
        "# test=test.drop(test.loc[:, 'limited_english':'veteran'].columns, axis=1)\n",
        "test=test.drop(test.loc[:, 'Average of Jan-13':'Average of Dec-18'].columns, axis=1)\n",
        "\n",
        "# id\n",
        "# test=test.drop(['patient_id'], axis=1)\n",
        "# a lot of null\n",
        "test=test.drop(['payer_type','bmi'], axis=1)\n",
        "# basically empty\n",
        "test=test.drop(['metastatic_first_novel_treatment','metastatic_first_novel_treatment_type'], axis=1)\n",
        "# one unique\n",
        "test=test.drop(['patient_gender'], axis=1)\n"
      ],
      "metadata": {
        "id": "oqJ4DF-ViC-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Filling NA (Categorical/Numerical)"
      ],
      "metadata": {
        "id": "A1kLidizrWIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling null values in patient race based on the races of residents in their area\n",
        "# Made the score worse -Noor\n",
        "# I made a change in the second for-loop and now it's making the score better -Khaled\n",
        "\n",
        "race_fill_value = {\n",
        "    'race_asian': 'Asian',\n",
        "    'race_black': 'Black',\n",
        "    'hispanic': 'Hispanic',\n",
        "    'race_white': 'White',\n",
        "}\n",
        "\n",
        "for row in train[train.patient_race.isnull()].index:\n",
        "    majority_race = pd.to_numeric(train.loc[row, 'race_white':'hispanic'], errors='coerce').idxmax()\n",
        "    train.loc[row, 'patient_race'] = race_fill_value.get(majority_race, 'Other')\n",
        "\n",
        "\n",
        "# Repeating it on test\n",
        "# Here it was test[train.patient_race.isnull()].index -Khaled\n",
        "for row in test[test.patient_race.isnull()].index:\n",
        "    majority_race = pd.to_numeric(test.loc[row, 'race_white':'hispanic'], errors='coerce').idxmax()\n",
        "    test.loc[row, 'patient_race'] = race_fill_value.get(majority_race, 'Other')"
      ],
      "metadata": {
        "id": "4eSULFuFuRqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VqfXP8fozvry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cats = train.select_dtypes(include=['object']).columns.tolist()\n",
        "nums = [x for x in train.columns if x not in cats][:-1]"
      ],
      "metadata": {
        "id": "nP7PqtYJdIgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[nums] = train[nums].fillna(train[nums].mean())\n",
        "test[nums] = test[nums].fillna(test[nums].mean())\n",
        "\n",
        "train[cats] = train[cats].fillna(train[cats].mode().iloc[0])\n",
        "test[cats] = test[cats].fillna(test[cats].mode().iloc[0])"
      ],
      "metadata": {
        "id": "5L3iUKkyfnuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fixing Inconsistency"
      ],
      "metadata": {
        "id": "ofjstB3Ul37D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['breast_cancer_diagnosis_desc'].replace({'Malig neoplasm of upper-outer quadrant of right male breast':\\\n",
        "                                               'Malignant neoplasm of upper-outer quadrant of right female breast', \\\n",
        "                                               'Malignant neoplasm of unspecified site of left male breast':\\\n",
        "                                               'Malignant neoplasm of unspecified site of left female breast', \\\n",
        "                                               'Malig neoplasm of upper-inner quadrant of right male breast':\\\n",
        "                                               'Malignant neoplasm of upper-inner quadrant of right female breast', \\\n",
        "                                               'Malignant neoplasm of central portion of left male breast':\\\n",
        "                                               'Malignant neoplasm of central portion of left female breast'}, inplace=True)"
      ],
      "metadata": {
        "id": "mWoo06drl-eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# thanks @iqbalsyahakbar\n",
        "# thanks THIAGO MANTUANI\n",
        "rep = {\n",
        "    'malig ' : '',\n",
        "    'malignant ' : '',\n",
        "    'neoplm ' : '',\n",
        "    'neoplasm ' : '',\n",
        "    'unsp ' : 'unspecified ',\n",
        "    'ovrlp' : 'overlapping',\n",
        "    'sites' : 'site',\n",
        "    'site,' : 'site',\n",
        "    'breast,' : 'breast',\n",
        "    'areola,' : 'areola',\n",
        "    '(female),' : 'female',\n",
        "    'of ' : '',\n",
        "    ' and ' : ' ',\n",
        "    '-' : ' '\n",
        "}\n",
        "rep = dict((re.escape(k), v) for k, v in rep.items())\n",
        "pattern = re.compile(\"|\".join(rep.keys()))\n",
        "\n",
        "train['breast_cancer_diagnosis_desc'] = train.breast_cancer_diagnosis_desc.astype('str').apply(\n",
        "    lambda x: pattern.sub(lambda m: rep[re.escape(m.group(0))], x.lower())\n",
        ")\n",
        "test['breast_cancer_diagnosis_desc'] = test.breast_cancer_diagnosis_desc.astype('str').apply(\n",
        "    lambda x: pattern.sub(lambda m: rep[re.escape(m.group(0))], x.lower())\n",
        ")\n",
        "\n",
        "#train['breast_cancer_diagnosis_desc'].unique()"
      ],
      "metadata": {
        "id": "leoAqu3XnS5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I tried sth but it didn't work :,)  -Noor\n",
        "# I changed some stuff and now it's working -Khaled\n",
        "# It keeps saying 'patient_state' and 'breast_cancer_diagnosis_code' doesnt exist\n",
        "# And that the number of rows in train and test don't match\n",
        "\n",
        "\n",
        "# # thanks simonagradinaru\n",
        "\n",
        "# Changing some states to match the correct zipcodes\n",
        "train['patient_state'] = np.where(train['patient_zip3'] == 630, 'MO', np.where(train['patient_zip3'] == 864, 'AZ', train['patient_state']))\n",
        "\n",
        "# Fixing the Division Missouri belongs to\n",
        "train['Division'] = np.where(train['patient_state'] == 'MO', 'West North Central', train['patient_state'])\n",
        "\n",
        "# Fixing inconsistencies in population for some patients\n",
        "pop_cols = train.loc[:, 'population':'veteran'].columns.to_list()\n",
        "\n",
        "train.loc[train.patient_id == 714510, pop_cols] = train.loc[train.patient_id == 636245, pop_cols].values\n",
        "train.loc[train.patient_id == 271422, pop_cols] = train.loc[train.patient_id == 271245, pop_cols].values\n",
        "train.loc[train.patient_id == 441322, pop_cols] = train.loc[train.patient_id == 982003, pop_cols].values\n",
        "\n",
        "#  Changing the 3 digit breast_cancer_diagnosis_code to be 4 digits\n",
        "train['breast_cancer_diagnosis_code'] = train['breast_cancer_diagnosis_code'].replace({'C509': 'C5091'})\n",
        "\n",
        "\n",
        "#### Repeating the steps for test\n",
        "\n",
        "test['patient_state'] = np.where(test['patient_zip3'] == 630, 'MO', np.where(test['patient_zip3'] == 864, 'AZ', test['patient_state']))\n",
        "\n",
        "train['Division'] = np.where(train['patient_state'] == 'MO', 'West North Central', train['patient_state'])\n",
        "\n",
        "pop_cols = test.loc[:, 'population':'veteran'].columns.to_list()\n",
        "\n",
        "test.loc[test.patient_id == 714510, pop_cols] = test.loc[test.patient_id == 636245, pop_cols].values\n",
        "test.loc[test.patient_id == 271422, pop_cols] = test.loc[test.patient_id == 271245, pop_cols].values\n",
        "test.loc[test.patient_id == 441322, pop_cols] = test.loc[test.patient_id == 982003, pop_cols].values\n",
        "\n",
        "test['breast_cancer_diagnosis_code'] = test['breast_cancer_diagnosis_code'].replace({'C509': 'C5091'})"
      ],
      "metadata": {
        "id": "0SycXt9FaCl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping id\n",
        "train=train.drop(['patient_id'], axis=1)\n",
        "test=test.drop(['patient_id'], axis=1)"
      ],
      "metadata": {
        "id": "x891WfxY7oGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Converting Categorical to Numerical"
      ],
      "metadata": {
        "id": "mdVUsQF0rc1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27126db7-66da-4548-ebbf-71ee967dddbb",
        "id": "riBJOT87gdDQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13173, 71)\n",
            "(5646, 70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data_train = pd.get_dummies(train[cats])\n",
        "                          #drop_first = True)\n",
        "train = pd.concat([train, encoded_data_train], axis=1)\n",
        "\n",
        "encoded_data_test = pd.get_dummies(test[cats])\n",
        "test = pd.concat([test, encoded_data_test], axis=1)"
      ],
      "metadata": {
        "id": "1LDzrnZAh3XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # This helped with the score - Khaled\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for i in cats:\n",
        "  train[i + '_encoded'] = label_encoder.fit_transform(train[i])\n",
        "  test[i + '_encoded'] = label_encoder.fit_transform(test[i])\n",
        "\n",
        "train = train.drop(cats, axis=1)\n",
        "test = test.drop(cats, axis=1)"
      ],
      "metadata": {
        "id": "ZTDUUjFUAXqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cats"
      ],
      "metadata": {
        "id": "Vpl5uJP9E3Pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73803040-5ef1-4b12-e483-aea5dc72bd8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['patient_race',\n",
              " 'patient_state',\n",
              " 'Region',\n",
              " 'Division',\n",
              " 'breast_cancer_diagnosis_code',\n",
              " 'breast_cancer_diagnosis_desc',\n",
              " 'metastatic_cancer_diagnosis_code']"
            ]
          },
          "metadata": {},
          "execution_count": 553
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2NS-mpXZmCn",
        "outputId": "f30b24d9-b44b-4816-c8cb-91aba43168a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13173, 300)\n",
            "(5646, 251)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Missing Columns (one-hot) in Train/Test"
      ],
      "metadata": {
        "id": "O9qL0SRnzGOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([train.drop(columns=\"metastatic_diagnosis_period\"), test])\n",
        "\n",
        "cols_not_common = []\n",
        "for index, value in df.isna().sum().items():\n",
        "    if value > 0:\n",
        "        #print(index, value)\n",
        "        cols_not_common.append(index)\n",
        "\n",
        "for col in cols_not_common:\n",
        "  if col not in train.columns:\n",
        "    train[col] = 0\n",
        "  if col not in test.columns:\n",
        "    test[col] = 0\n",
        "\n",
        "test = test.reindex(columns=sorted(test.columns))\n",
        "train = train.reindex(columns=sorted(train.columns))\n",
        "\n",
        "df.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "1E-MgshFpCrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Removing Duplicate rows"
      ],
      "metadata": {
        "id": "rPEyJshraaPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I changed the model used from random forest to catboost and it gave the exact same score\n",
        "# And both models had missing values in the submission file - Khaled\n",
        "\n",
        "# train.drop_duplicates(inplace=True)\n",
        "# test.drop_duplicates(inplace=True)\n",
        "\n",
        "# Dropping rows seems to always make the score worse - Khaled"
      ],
      "metadata": {
        "id": "mIeaEtgSaJQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.duplicated().sum(), train.shape)\n",
        "print(test.duplicated().sum(), test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYJAawuBxgQ3",
        "outputId": "4bbac648-fae5-454a-f12b-f01fce9a4cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22 (13173, 311)\n",
            "36 (5646, 310)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zGtxrtDCwvTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cor_train = train.corr()\n",
        "\n",
        "target = 'metastatic_diagnosis_period'\n",
        "alpha = 0.1\n",
        "cor_target = abs(cor_train[target])\n",
        "\n",
        "relevant_features = cor_target[cor_target>alpha]\n",
        "print(len(relevant_features))\n",
        "relevant_features\n",
        "# I think that these correlations are really bad, especially as the highest one is 0.536860"
      ],
      "metadata": {
        "id": "K2DgEZT9_f8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "909573fc-4978-4273-c979-6dada8305433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "breast_cancer_diagnosis_code_1744                                          0.207609\n",
              "breast_cancer_diagnosis_code_1748                                          0.191176\n",
              "breast_cancer_diagnosis_code_1749                                          0.498996\n",
              "breast_cancer_diagnosis_code_C50411                                        0.105243\n",
              "breast_cancer_diagnosis_code_C50911                                        0.136724\n",
              "breast_cancer_diagnosis_code_C50912                                        0.145692\n",
              "breast_cancer_diagnosis_code_C50919                                        0.132038\n",
              "breast_cancer_diagnosis_code_encoded                                       0.536860\n",
              "breast_cancer_diagnosis_desc_breast female unspecified                     0.498996\n",
              "breast_cancer_diagnosis_desc_encoded                                       0.407334\n",
              "breast_cancer_diagnosis_desc_other specified site female breast            0.191176\n",
              "breast_cancer_diagnosis_desc_unspecified site left female breast           0.145737\n",
              "breast_cancer_diagnosis_desc_unspecified site right female breast          0.136724\n",
              "breast_cancer_diagnosis_desc_unspecified site unspecified female breast    0.132038\n",
              "breast_cancer_diagnosis_desc_upper outer quadrant female breast            0.207609\n",
              "breast_cancer_diagnosis_desc_upper outer quadrant right female breast      0.105435\n",
              "metastatic_diagnosis_period                                                1.000000\n",
              "Name: metastatic_diagnosis_period, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 558
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZEfKE_I3xO2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train[relevant_features.index]"
      ],
      "metadata": {
        "id": "g9dI2rA5dS27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Creation"
      ],
      "metadata": {
        "id": "4lUO-ZmezPno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = train.drop('metastatic_diagnosis_period', axis = 1)\n",
        "y = train['metastatic_diagnosis_period']"
      ],
      "metadata": {
        "id": "_LvNgN0wjnqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "random_forest = RandomForestRegressor(n_estimators=100,\n",
        "                                max_depth=10,\n",
        "                                min_samples_split=2,\n",
        "                                min_samples_leaf=1,\n",
        "                                max_features='auto',\n",
        "                                bootstrap=True,\n",
        "                                random_state=42,\n",
        "                                criterion='friedman_mse',\n",
        "                                min_impurity_decrease=0.0,\n",
        "                                oob_score=False)\n",
        "\n",
        "# Train the model\n",
        "random_forest.fit(x, y)\n",
        "\n",
        "# Make predictions\n",
        "predictions = random_forest.predict(x)\n",
        "\n",
        "# # Calculate accuracy\n",
        "# accuracy = accuracy_score(y, predictions)\n",
        "# print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mse = mean_squared_error(y, predictions, squared=False)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "id": "KMjW4c8LjUnv",
        "outputId": "53b49ae2-9119-404f-ff6d-6a86f5f98f3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 72.75526537803995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "id": "FFGws9HXAdiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8390d1-24f9-4c9e-ede6-5a490a0788ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 81.43103479  58.05409521 222.81583615 ...  60.69658018 274.40427537\n",
            "  50.35090041]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Instantiate the XGBoost regressor\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',  # Objective function for regression\n",
        "    'colsample_bytree': 0.3,          # Fraction of features to sample for each tree\n",
        "    'learning_rate': 0.01,            # Step size shrinkage used in update to prevent overfitting\n",
        "    'max_depth': 20,                  # Maximum depth of a tree\n",
        "    'alpha': 10,                      # L1 regularization term on weights\n",
        "    'n_estimators': 50,               # Number of boosting rounds (trees)\n",
        "    'min_child_weight': 2,            # Minimum sum of instance weight needed in a child\n",
        "    'gamma': 0.1,                     # Minimum loss reduction required to make a further partition on a leaf node\n",
        "    'subsample': 0.95                  # Fraction of samples used in each boosting round\n",
        "    #'reg_lambda': 1.0                 # L2 regularization term on weights\n",
        "}\n",
        "\n",
        "# Instantiate the XGBoost regressor\n",
        "xgb_reg = xgb.XGBRegressor(**params)\n",
        "# Fit the model to the training data\n",
        "xgb_reg.fit(x, y)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "xboost_pred = xgb_reg.predict(x)\n",
        "\n",
        "# Evaluate the model\n",
        "mse2 = mean_squared_error(y, xboost_pred, squared=False)\n",
        "print(\"Mean Squared Error:\", mse2)"
      ],
      "metadata": {
        "id": "UR8XtltTAUB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8bbdf80-d0b1-468e-824c-ee441b67fdd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 85.76629180408989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "pML6EDbfFk8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be0b84e6-ba9b-40ee-f442-9cd6b925c724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRegressor\n",
        "\n",
        "params = {\n",
        "    'iterations': 100,                # Number of trees to build (equivalent to n_estimators)\n",
        "    'depth': 7,                       # Depth of the trees,6                                                           - I got stupid and put the depth at 15. Wouldn't recommend.\n",
        "    'learning_rate': 0.1,             # Step size shrinkage used in update to prevent overfitting\n",
        "    'l2_leaf_reg': 4,                 # L2 regularization term on leaf weights\n",
        "    'bagging_temperature': 1.0,       # Controls the intensity of the temperature (the higher the value, the more aggressive the bagging)\n",
        "    'random_strength': 1.0,           # The strength of the random permutation that is used to make the splits\n",
        "    'border_count': 254,              # Approximation parameter for dealing with categorical features\n",
        "    'thread_count': 4,                # The number of parallel threads used to train the model,\n",
        "    'verbose': False                  # Whether to print information during training\n",
        "}\n",
        "\n",
        "# Instantiate the CatBoost regressor\n",
        "catboost_reg = CatBoostRegressor(**params)\n",
        "\n",
        "# Fit the model to the training data\n",
        "catboost_reg.fit(x, y)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "cat_pred = catboost_reg.predict(x)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y, cat_pred, squared=False)\n",
        "print(\"Root Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiZ9cuh9FW6M",
        "outputId": "ae0dc9b9-08f3-4d77-ff2c-772c08116957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error: 78.61246857872068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting"
      ],
      "metadata": {
        "id": "xYe13R35zWau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Catboost seems to give the best results so far -Noor\n",
        "y_test = catboost_reg.predict(test)\n",
        "cat_pred = catboost_reg.predict(test)\n",
        "xboost_pred = xgb_reg.predict(test)\n",
        "predictions = random_forest.predict(test)"
      ],
      "metadata": {
        "id": "TkqMM8s3omCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_preds = np.average([cat_pred, xboost_pred], weights=[0.6, 0.5], axis=0)\n",
        "# Don't know what I did but it made the score worse - Khaled"
      ],
      "metadata": {
        "id": "90gzCcx_xy3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.concat([patients, pd.Series(y_test, name='metastatic_diagnosis_period')], axis = 1)\n",
        "\n",
        "#submission['metastatic_diagnosis_period'] = ensemble_preds+0.4\n",
        "\n",
        "submission['metastatic_diagnosis_period'] = submission['metastatic_diagnosis_period'].round().astype(int)\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "files.download('submission.csv')"
      ],
      "metadata": {
        "id": "0zr6UE3AnT2u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e71039af-5f77-4624-d92e-aa20d1846b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a79f783b-89cf-4241-b0aa-55ce530813dc\", \"submission.csv\", 57895)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i7m7ih9X1ZJl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}